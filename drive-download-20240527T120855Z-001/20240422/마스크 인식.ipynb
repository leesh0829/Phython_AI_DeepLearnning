{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1mFls4mNuuhsOdKPTSQxjVVAayK8Vew-D","authorship_tag":"ABX9TyP0iq131EEcYb4jztpV9Wyx"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qC_IDjWEdiJI","executionInfo":{"status":"ok","timestamp":1713953696989,"user_tz":-540,"elapsed":9035,"user":{"displayName":"이승현","userId":"07229250747494155738"}},"outputId":"f0bf119d-23f3-4fe8-ffb1-302cc97531fc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["HOME = '/content/drive/MyDrive/20240422'\n","\n","import os\n","%cd {HOME}"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HaKnGJksdxp5","executionInfo":{"status":"ok","timestamp":1713953696989,"user_tz":-540,"elapsed":2,"user":{"displayName":"이승현","userId":"07229250747494155738"}},"outputId":"41afc07a-004c-424e-c8b6-4c8bd05583fd"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/20240422\n"]}]},{"cell_type":"code","source":["import cv2\n","import numpy as np\n","from google.colab.patches import cv2_imshow\n","from tensorflow import keras\n","from keras.applications.mobilenet_v2 import preprocess_input\n","from keras.models import load_model"],"metadata":{"id":"-JrSwpB_eZfC","executionInfo":{"status":"ok","timestamp":1713953701846,"user_tz":-540,"elapsed":4466,"user":{"displayName":"이승현","userId":"07229250747494155738"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["!pip install ffmpeg-python\n","\n","import ffmpeg\n","from base64 import b64encode\n","from IPython.display import HTML\n","\n","def get_video_metadata(video_path):\n","    try:\n","        probe = ffmpeg.probe(video_path)\n","        video_stream = next((stream for stream in probe['streams'] if stream['codec_type'] == 'video'), None)\n","        return {\n","            'video_codec': video_stream['codec_name'] if video_stream else 'None',\n","        }\n","    except Exception as e:\n","        return {'error': str(e)}\n","\n","def convert_video_to_h264(input_path, output_path):\n","    try:\n","        ffmpeg.input(input_path).output(output_path, vcodec='libx264').run(overwrite_output=True)\n","        return True\n","    except ffmpeg.Error as e:\n","        return False\n","\n","def check_and_convert_video(video_path):\n","    metadata = get_video_metadata(video_path)\n","\n","    if metadata.get('error'):\n","        return f\"Error retrieving metadata: {metadata['error']}\", 0\n","\n","    if metadata['video_codec'] == 'mpeg4':\n","        output_path = video_path.replace('.mp4', '_converted.mp4')\n","        success = convert_video_to_h264(video_path, output_path)\n","        if success:\n","            return output_path, 1\n","        else:\n","            return \"Failed to convert video.\",0\n","    else:\n","        return video_path, 2\n","\n","def play_video(video_path):\n","\n","    play_video_file, result = check_and_convert_video(video_path)\n","\n","    if result!=0:\n","        # ��������� ��������� ������ base64��� ���������\n","        try:\n","            with open(play_video_file, \"rb\") as video_file:\n","                video_encoded = b64encode(video_file.read()).decode('ascii')\n","\n","            # HTML ������ ������\n","            video_html = f'''\n","            <video width=800 controls>\n","            <source src=\"data:video/mp4;base64,{video_encoded}\" type=\"video/mp4\">\n","            </video>\n","            '''\n","            display(HTML(video_html))\n","        except Exception as e:\n","            print(f\"Error: {e}\")\n","    else :\n","        print(\"unknown file!!!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_9E-Nnunfiqp","executionInfo":{"status":"ok","timestamp":1713953709988,"user_tz":-540,"elapsed":8144,"user":{"displayName":"이승현","userId":"07229250747494155738"}},"outputId":"c92ea8a0-b74a-43ea-8de6-0237d1610599"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting ffmpeg-python\n","  Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n","Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from ffmpeg-python) (0.18.3)\n","Installing collected packages: ffmpeg-python\n","Successfully installed ffmpeg-python-0.2.0\n"]}]},{"cell_type":"code","source":["facenet = cv2.dnn.readNet('models/deploy.prototxt', 'models/res10_300x300_ssd_iter_140000.caffemodel')\n","model = load_model('models/mask_detector.model')\n","\n","cap = cv2.VideoCapture('videos/mask.mp4')\n","\n","fourcc = cv2.VideoWriter_fourcc('m', 'p', '4', 'v')\n","\n","out = cv2.VideoWriter('output.mp4', fourcc, cap.get(cv2.CAP_PROP_FPS), (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))))\n","\n","while cap.isOpened():\n","  ret, img = cap.read()\n","\n","  if not ret:\n","    break\n","\n","  h, w, c = img.shape\n","\n","  blob = cv2.dnn.blobFromImage(img, size = (300, 300), mean = (104., 177., 123.))\n","\n","  facenet.setInput(blob)\n","  dets = facenet.forward()\n","\n","  for i in range(dets.shape[2]):\n","    confidence = dets[0, 0, i, 2]\n","\n","    if confidence < 0.5:\n","      continue\n","\n","    x1 = int(dets[0, 0, i, 3] * w)\n","    y1 = int(dets[0, 0, i, 4] * h)\n","    x2 = int(dets[0, 0, i, 5] * w)\n","    y2 = int(dets[0, 0, i, 6] * h)\n","\n","    face = img[y1:y2, x1:x2]\n","\n","    face_input = cv2.resize(face, dsize=(224,224))\n","    face_input = cv2.cvtColor(face_input, cv2.COLOR_BGR2RGB)\n","    face_input = preprocess_input(face_input)\n","    face_input = np.expand_dims(face_input, axis=0)\n","\n","    mask, nomask = model.predict(face_input).squeeze()\n","\n","    if mask > nomask :\n","      color = (0, 255, 0)\n","    else:\n","      color = (0, 0, 255)\n","      cv2.putText(img, text = '%', fontFace = cv2.FONT_HERSHEY_SIMPLEX, fontScale = 1, color = (0, 255, 0), thickness = 2)\n","\n","    cv2.rectangle(img, pt1=(x1, y1), pt2=(x2, y2), thickness=2, color=color)\n","\n","  out.write(img)\n","\n","out.release()\n","\n","play_video('output.mp4')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1b7PqrKhqNBEnUpizmhN461itGvaO6JZm"},"id":"n9mWcgj5fy0K","executionInfo":{"status":"ok","timestamp":1713941818622,"user_tz":-540,"elapsed":252575,"user":{"displayName":"이승현","userId":"07229250747494155738"}},"outputId":"7158e13c-8d3a-4361-bd99-13d88a61c095"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["facenet = cv2.dnn.readNet('models/deploy.prototxt', 'models/res10_300x300_ssd_iter_140000.caffemodel')\n","model = load_model('models/mask_detector.model')\n","\n","cap = cv2.VideoCapture('videos/mask3.mp4')\n","\n","fourcc = cv2.VideoWriter_fourcc('m', 'p', '4', 'v')\n","\n","out = cv2.VideoWriter('output1.mp4', fourcc, cap.get(cv2.CAP_PROP_FPS), (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))))\n","\n","while cap.isOpened():\n","  ret, img = cap.read()\n","\n","  if not ret:\n","    break\n","\n","  h, w, c = img.shape\n","\n","  blob = cv2.dnn.blobFromImage(img, size = (300, 300), mean = (104., 177., 123.))\n","\n","  facenet.setInput(blob)\n","  dets = facenet.forward()\n","\n","  for i in range(dets.shape[2]):\n","    confidence = dets[0, 0, i, 2]\n","\n","    if confidence < 0.5:\n","      continue\n","\n","    x1 = int(dets[0, 0, i, 3] * w)\n","    y1 = int(dets[0, 0, i, 4] * h)\n","    x2 = int(dets[0, 0, i, 5] * w)\n","    y2 = int(dets[0, 0, i, 6] * h)\n","\n","    face = img[y1:y2, x1:x2]\n","\n","    face_input = cv2.resize(face, dsize=(224,224))\n","    face_input = cv2.cvtColor(face_input, cv2.COLOR_BGR2RGB)\n","    face_input = preprocess_input(face_input)\n","    face_input = np.expand_dims(face_input, axis=0)\n","\n","    mask, nomask = model.predict(face_input).squeeze()\n","\n","    if mask > nomask :\n","      color = (0, 255, 0)\n","      label = 'Mask %d%%' % (mask * 100)\n","    else:\n","      color = (0, 0, 255)\n","      label = 'nomask %d%%' % (nomask * 100)\n","\n","    cv2.putText(img, text = label, org = (x1, y1), fontFace = cv2.FONT_HERSHEY_SIMPLEX, fontScale = 1, color = (color), thickness = 2)\n","\n","    cv2.rectangle(img, pt1=(x1, y1), pt2=(x2, y2), thickness=2, color=color)\n","\n","  out.write(img)\n","\n","out.release()\n","\n","play_video('output1.mp4')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1xErer70eHB1cHzf68r-Jm9BnDeN-ldVu"},"id":"DtQJpvzx8Q1c","executionInfo":{"status":"ok","timestamp":1713953998177,"user_tz":-540,"elapsed":152561,"user":{"displayName":"이승현","userId":"07229250747494155738"}},"outputId":"b4041e43-e810-4052-8e57-b606a8fd2b89"},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]}]}